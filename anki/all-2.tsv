Array: largest rectangle under histogram	iterate on bars: find <b>largest rectangle to the left with this bar and height</b><br><br><b>efficient frontier:</b> keep only past building with <b>increasing height (stack)</b><br><br>O(n)
Array: length of longest increasing subsequence	- O(n^2) bestLISEndingAtOffset[i]<br><br>- O(n log n) <b>active lists</b> (duplicate and extend)<br>or <b>tail array</b>: t[i] smallest tail of all increasing subsequences with length i+1<br><b>update cell or extend</b>
Array: longest increasing <b>subarray</b><br>+ trick	<b>one pass</b> O(n)<br><br>--<br>trick: if current max is L<br><b>skip</b> L chars and check in <b>reverse order first</b><br><br>improves best-case complexity<br>but not worst-case
Array: skyline<br>how to solve, complex	 <b>divide and conquer</b><br>similar to merge sort<br><br>- divide in <b>2 equal sets</b> (no order or sort)<br>- compute skyline for each<br>- <b>merge</b>: <b>iterate</b> on both<br><br>O(n log n)
Array: split array in m continous subarrays<br>minimize largest subarray sum	<b>Binary search</b> on answer<br><br>Greedy packing to check if valid
Binary Search: find <b>first</b> element (2)	- tweak binary search<br><br>- or set <b>currentBest variable</b> and continue
Bit: test if a number is a power of two	(n & (n-1)) == 0
Combinatorics: compute<br>subsets of a set<br>permutations of a set	subsets: recursive, or iterative<br><br>permutations: recursive
DS HashTable: hash table strategies (3)	chaining: <b>linked lists</b><br><br><b>open adressing</b>: next position<br><br><b>double hashing</b>
DS Heap: algorithm and complexity	heapify <b>from the lower levels</b> first,<br><b>sinkdown</b> nodes<br><br>O(n)
DS Heap: complexity and algo of insert, extract-min, search	use <b>last element</b>, bubble up or down<br>O(log n)<br><br>search: difficult O(n)
DS Heap: from max-heap, check if k-th largest element is >= x in O(k)/O(k)	<b>recursive</b><br>gradual descent with larger/equal counters<br><br>stop early<br><br>nb calls is O(k) as counters are almost always incremented
DS Heap: specialized heaps (2)	when <b>limited set</b> of keys,<br><br>or <b>monotonic</b> input
DS Priority Queue: 6 example use of a priority queue	- continous top k<br>- k-way merge<br>- continous median<br>- sort when only k indices away<br>- heapsort/tree sort<br>- Dijkstra/Prim
DS Priority Queue: monotonic priority queue<br>def, examples	min monotonic: inserted elements have <b>higher prio than min</b> of heap<br><br>ie. will not become min<br><br>Dijkstra, sweep line<br><br>can <b>optimize bucket queue</b>
DS Queue: implement a queue using two stacks	empty first stack into second stack
DS Stack: implement stack with O(1) min<br>(2 ways)	push (x, min) when pushing x, <br><br>or use second stack
DS Stack: sort a stack (2)	using a second stack<br><br>or recursively:<br>need 2 recursions:<br>sort, insert in sorted
DS/prob: HyperLogLog, def, use	<b>approximate count-distinct</b> with O(1) mem<br>hash stream entries and only record the <b>longest leading zero seq length</b><br><br>Improve with buckets, outliers and averaging<br><br>Use in ApproxCountDistinct in DBs.
DS/prob: check if item is in known set	<b>Bloom filter</b> if no space for hash table
DS/prob: countâ€“min sketch, def, use	probabilistic data structure: <b>frequency table of events</b> in a <b>stream</b> of data<br><br>same as <b>counting Bloom Filter</b><br><br><b>Table</b>: row=hash function, column: bucket (space of hash), entry: integer<br><br>ex: count views for many many videos
DS/prob: probabilistic data structures (3)	<b>Bloom</b> filter: set<br><br><b>Count-Min sketch</b>: count by type<br><br><b>HyperLogLog</b>: count
DS: <b>Interval tree</b>, search algo	red black tree<br>each node is interval<br><br>node contains:<br>1. start of interval=sort key<br>2. end of interval<br>3. maxEnd of intervals in subtree<br><br>search for intersection O(h):<br>go in right or left (bit tricky proof)
DS: <br>Binary heap definition	complete binary<br><br>with heap property (children smaller than parent)
DS: LFU cache<br>implementation	<b>3 hash maps</b>, one with linked list as values
DS: PriorityQueue <br>implementations (2) and stack (2)	- priority queue: <b>heap</b>, <b>BST</b><br><br>- stack: <b>linked list</b><br>or <b>array</b><br>(needs resizing, so amortized)
DS: PriorityQueue bucket queue<br>def, use case	<b>priority queue</b> when <b>restricted prio range</b><br>{0, 1, ..., C - 1}<br><br><b>array</b> of <b>C linked lists</b><br><br>to find min, search non-empty list from i=0: O(C)<br>(optimizations possible)<br><br>insert: O(1)
DS: Union-find: naive + 2 optimizations.<br>Complexity.	naive: attach root of x to root of y. <br>Union by rank: attach smaller tree to larger. <br>Path compression<br><br>Amortized O(1) in time |O(n) space.
DS: implement LRU cache	= <b>DLL Queue + HashTable</b>: <br><br>queue: doubly linked list (size: cache size). MRU at front.<br><br>hash: address of the queue node as value
DS: skip list<br>- definition<br>- complexities<br>- used in	linked list for binary search<br>layers of sorted linked lists (<b>express lanes</b>)<br>p = 1/2 or 1/4, proba for element to be also in layer below<br><br><b>O(log n)</b> average for search/insert/delete, O(n) average space<br>used in LevelDB MemTable
DS: tournament tree, def, use	complete binary tree<br>2 case: <b>winner</b>, <b>loser</b> tree<br><br>player=leaves<br>min/max winner/loser<br><br>apps: sorting, first-fit bin packing, k-way merge
DS: treap, def, use	<b>BST</b> and <b>heap</b><br><br>node is <b>pair</b> (x, y)<br>x: key in the <b>BST</b><br>y: key in the heap (<b>priority</b>)<br><br>random prio: will probably <b>make BST balanced</b>
Geo: 5 problems solved by sweep line	closest pair<br>union of rectangles<br>convex hull<br>line intersection<br>Voronoi diagrams
Geo: convex-hull algorithm (3)	wrapping O(nh)<br><br>sweep line O(n log n)<br><br>divide and conquer O(n log n)
Geo: find 4th point of rectangle	just use <b>vector</b><br><br>a + (b - c)
Geo: k-d tree<br>definition<br>4 complexities	split in 1 dimension at each node (median of coordinate to get balance)<br><br>search/insert/delete O(log n) average<br>Space: O(n)
Geo: line through most points	<b>hash</b><br>H[line] = list of points<br><br>for each pair, add entry in H<br><br>tricky hash because floats<br>use rationals
Geo: quad-tree	2D hierarchical partition in quadrants<br><br><b>4</b> children by node<br>split when max capacity reached.
Graph/co: Find connected components of an undirected graph (2)	<b>- BFS/DFS</b> O(V + E), <br><br>- <b>or</b> process <b>edges</b>, <b>Union-Find</b> on vertices<br><br>If <b>dynamic</b> changes, keep track of components with <b>Union-Find</b>.
Graph/co: Strongly Connected Components<br>definition and algo name/cplx	subgraphs s.t. if every vertex is reachable from every other vertex<br><br>K: first DFS topological sort<br>second DFS in inverse graph collect SCC<br><br>T: only one pass<br>O(V + E)
Graph/co: transitive closure def, algo	= reachable[s][t] matrix<br><br><b>(if undirected: = easy connected-co)</b><br><br>directed (2):<br><br>1. DFS on each vertex to fill reachable[src][*]<br>O(V (V + E))<br><br>2. or <b>Floyd-Warshall-like</b> O(n^3)
Graph/cycle: Eulerian cycle: def, check/find algos	visit each edge<br><br>linear time O(E)<br>vs. Hamiltonian is NP-hard<br><br>check if exists: look at conditions on degree<br><br>find: O(E) exists (Fleury)
Graph/cycle: how to check for negative weight cycles	<b>Bellman-Ford</b><br><br>run the <b>relaxing-loop once more</b><br>if relaxing decreases distance to a vertex, then there is a negative cycle<br><br>O(VE)
Graph/paths: 4 SSSP/APSP algs	- BFS<br>- Dijkstra: O(V^2) or less with heap. Greedy closest edge.<br><br>- Bellman-Ford: O(VE) OK with negative weights, no cycles. Relax all edges |V| times<br><br>- Floyd-Warshall: same as Bellman-Ford but all pairs. O(V^3)/O(V^2)
Graph/paths: A*: idea, difference with dijkstra	choose vertex which score minimizing distance processed vertices and <b>distance to target</b>
Graph/paths: longest path from vertex in weighted graph<br>+ DAG	NP-hard for general graph<br>naive Bruteforce E!<br><br>linear for DAG: toposort, then loop<br>O(V + E)
Graph/paths: number of paths from src to dest with k edges (2)	1. DP <b>numPaths[src][dest][edges]</b><br>O(k V^3)<br><br>2. Divide and Conquer <b>matrix power</b> G^k<br>O(log k) matrix power<br>total: O(V^3 log k)
Graph/paths: print number of paths with no cycle between two nodes in a directed graph	<b>backtracking</b><br><br>set/unset visited nodes
Graph/paths: shortest path with a max delay constraint (edges have weight and delay)	<b>memoized DP</b><br>dp[destinationVertex,withDelay]<br><br>O(E maxDelay)
