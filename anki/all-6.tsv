SD primitives: Gossip	probabilistic technique for <b>synchronizing replicas</b><br><br>nodes have some probability p of attempting to synchronize with each other<br><br>efficient thanks to <b>Merkle trees</b>
SD primitives: N, R, W, usual recommendation	N replicas,<br>need R/W votes for read/write<br>R + W > N
SD primitives: WAL<br>def, goal	<b>write-ahead logging</b><br><b>first log</b> actions to be done to permanent storage<br><br><b>then do</b> the actions<br><br>gives <b>durability</b> and atomicity even if crash
SD primitives: disadvantage of master-master replication	loosely consistent (violating ACID) or big write latency due to synchronization
SD primitives: how a Lamport clock works	when a process does work, increment<br>when send a message, include counter<br>when message received, take the <b>max</b> counter of self and message
SD primitives: primary/backup replication<br>master, works how, network, failover	single, static master<br>replicated log: slaves execute<br>no bound on operation delay<br>not partition tolerant<br>manual/ad-hoc failover, not fault tolerant<br>synchronous variant: ensure that write are done one backups before returning to the client
SD primitives: replace global clock by?<br>based on?	vector clock<br><br><br>(t1, ..., tN)<br>based on Lamport clock
SD primitives: split brain	failover to backup due to temporary network issue<br>primary and backup are active at the same time
SD/acid: A in ACID	Atomicity<br><br>All or nothing for a transaction:<br>indivisible<br><b>done or not done</b>
SD/acid: C in ACID	Consistency<br><br>a transaction moves the DB from a <b>valid state to other valid state</b> (e.g. preserve unique keys)<br><br>Not the same as C in CAP
SD/acid: D in ACID	when a transaction is committed, it will <b>remain committed</b> even in the case of a system failure (power, crash)
SD/acid: I in ACID	concurrent execution of transactions leaves the DB in same state than if the they were executed sequentially
SD/cap: Availability in CAP theorem (2)	every request receives a response about its success<br><br>or any reachable replica is available for reads and writes
SD/cap: Consistency in CAP theorem	all nodes see the same data all the time<br><br>equivalent to <b>single-copy</b> of the data
SD/cap: Partition tolerance in CAP theorem	system continues to operate despite message loss or failure of part of the system
SD/cons: tunable consistency	from "writes never fail" to <br><br>"block for all replicas to be readable" with quorum levels
SD/para: <b>synchronized</b> Java primitive	used to define a <b>critical section</b><br><br>only <b>one thread</b> can enter block of code<br><br>can be used on code blocks or methods
SD/para: Deadlock (def, example)	task waits forever for conditions that can not be met<br><br>tasks wait for other tasks<br><br>ex: 2 tasks with 2 resources with each 1 lock<br>dining philosophers
SD/para: dining philosophers problem, solutions (2)	round table, knife/fork<br><br>1. request <b>smaller index</b> resources first<br><br>or 2. add <b>arbitrator</b>
SD/para: how to <b>avoid deadlock</b>	make <b>locking order fixed</b> when multiple locks
SD/para: livelock	2+ processes change their states in response to changes in the other process(es), no useful work<br><br>ex. corridor
SD/para: mutex	one thread in <b>critical section</b> at a time
SD/para: producer-consumer problem, solution	fixed size buffer<br>ensure that don't read if empty, don't write if full<br><br>use <b>2 semaphores</b>: remainingSpace, currentItems
SD/para: readers-writers problem (3 variations)	<b>multiple readers</b> at the same time<br>only <b>1 writer</b><br><br>1. readers preference (can starve writers)<br>2. writers preference (starve readers)<br>3. fairness
SD/para: semaphore	<b>count</b> how many units of resources are available<br><br>safe operations to modify count<br><br>counting/binary semaphore
SD/para: starvation	runnable process is overlooked indefinitely by the scheduler<br><br>although it is able to proceed, it is never chosen
SD/para: thread model for a web server	use <b>thread pool</b><br><br><b>avoids overhead</b> when create/delete<br>caps <b>maxThreads</b><br><br>use <b>synchronized task queue</b>
SD/store: Denormalization	improve read perf at the expense of write perf. <br>Redundant copies of the data are written in multiple tables to avoid expensive joins. 
SD/store: Federation	= functional partitioning<br><br>splits up databases by function. <br><br>For example, forums, users, and products
SD/store: NoSQL	 is a collection of data items represented in a key-value store, document-store, wide column store, or a graph database. <br>Data is denormalized, and joins are generally done in the application code.
SD/store: types of data store (9)	RDBMS<br>k/v<br>document<br>column-family<br>graph<br>analytics<br>blob<br>search engine DB<br>time series DB
SD: 2 types of failover	active-passive (master-slave)<br><br>active-active (master-master)
SD: CQRS	command query responsibility separation<br><br>separate read and write of data
SD: Geo load-balancing with DNS	some DNS servers have IP range tables and can have different responses for different ranges
SD: How many simultaneous connections on a whatsapp server	2 million
SD: Master-master replication	Both masters serve reads and writes and coordinate with each other on writes. <br>If either master goes down, the system can continue to operate with both reads and writes.
SD: N+2 principle	other machines can absorb load if 2 largest instances are down<br><br>e.g. machine off or release
SD: SLO for S3 (2)	99.99 (4) availability<br><br>99.99999999 (10) durability
SD: circuit breaker<br>def, how it works	<b>~proxy</b> for operations that might fail<br><br><b>3 states</b>: closed / half-open / open<br>change state by looking at <b>error rate</b>
SD: classic consistency problem in DB	read-after-write
SD: def, usual value for <b>page size</b>	smallest unit of virtual memory<br><br><b>4KB</b><br><br>can be more
SD: drawback of DNS load balancing	results are cached by intermediate servers, so not responsive when change
SD: event-sourcing pattern	use append-only store of actions/events
SD: hashing for sharding (2)	<b>consistent hashing</b>: circle with many pseudo-random points per node<br><br><br><b>Rendezvous</b> hashing
SD: how many seconds in a day	90K
SD: how to send updates from server to client (3)	<b>short-polling</b> (client pull)<br><br><b>long-polling</b> (client pull): server doesn't answer request until new data<br><br><b>websocket</b> (server push): persistent bi-directionnal connnection over TCP less overhead than HTTP no need to do new TCP handshake
SD: in MySQL master-slave, how to ensure read-after-write has most recent value	read from Master
SD: replication lag for MySQL	time between read/write to master and replication to all slaves
SD: retry pattern	depending on error from service, client can have 3 strategies<br>- retry immediately<br>- retry later<br>don't retry<br><br>careful: idempotency prefered
